{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "hvJNfCifPHng",
        "outputId": "69f504d6-9829-447e-a787-b408ec66fad6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nYeh sab required libraries install karta hai:\\n\\nyfinance → stock data fetch\\n\\npandas/numpy → data handling\\n\\nmatplotlib → graph plotting\\n\\nscikit-learn → scaling\\n\\nkeras → LSTM neural network\\n\\ngradio → web UI\\n\\nflask → API endpoint\\n\\nfpdf2 → PDF report\\n\\nbs4 + requests → news scraping\\n\\ntransformers → FinBERT model for sentiment\\n\\npyTelegramBotAPI → Telegram alerts\\n\\ngTTS → text-to-speech\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "!pip install -q yfinance pandas numpy matplotlib scikit-learn keras gradio flask fpdf2 beautifulsoup4 requests transformers pyTelegramBotAPI gTTS\n",
        "# Required libraries install kar raha hai (finance, ML, visualization, NLP, chatbot, PDF, voice).\n",
        "\n",
        "\"\"\"\n",
        "Yeh sab required libraries install karta hai:\n",
        "\n",
        "yfinance → stock data fetch\n",
        "\n",
        "pandas/numpy → data handling\n",
        "\n",
        "matplotlib → graph plotting\n",
        "\n",
        "scikit-learn → scaling\n",
        "\n",
        "keras → LSTM neural network\n",
        "\n",
        "gradio → web UI\n",
        "\n",
        "flask → API endpoint\n",
        "\n",
        "fpdf2 → PDF report\n",
        "\n",
        "bs4 + requests → news scraping\n",
        "\n",
        "transformers → FinBERT model for sentiment\n",
        "\n",
        "pyTelegramBotAPI → Telegram alerts\n",
        "\n",
        "gTTS → text-to-speech\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf       # stock data download\n",
        "import pandas as pd         # data handling\n",
        "import numpy as np          # numerical calculations\n",
        "import matplotlib.pyplot as plt  # plotting graphs\n",
        "import gradio as gr         # web UI\n",
        "import requests             # fetch webpages\n",
        "from bs4 import BeautifulSoup  # web scraping\n",
        "from sklearn.preprocessing import MinMaxScaler  # data normalization\n",
        "from keras.models import Sequential             # NN container\n",
        "from keras.layers import LSTM, Dense            # LSTM layers for stock prediction\n",
        "from fpdf import FPDF                          # PDF report generator\n",
        "import datetime\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification  # FinBERT for news sentiment\n",
        "import os, sqlite3\n",
        "import telebot\n",
        "from flask import Flask, request, jsonify, send_file\n",
        "from gtts import gTTS       # Text-to-speech (voice summary)\n"
      ],
      "metadata": {
        "id": "lRkf0M0hPPeC"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "MODEL_NAME = \"ProsusAI/finbert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "sentiment_model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "label_map = {0: \"negative\", 1: \"neutral\", 2: \"positive\"}\n",
        "DB_FILE = \"stock_predictions.db\"\n",
        "BOT_TOKEN = \"YOUR_TELEGRAM_BOT_TOKEN\"\n",
        "CHAT_ID = \"YOUR_CHAT_ID\"\n",
        "\n",
        "\"\"\"\n",
        "Scaler → data ko 0–1 ke range me laya jata hai.\n",
        "\n",
        "FinBERT model → financial sentiment analysis ke liye pretrained model.\n",
        "\n",
        "DB_FILE → SQLite database file.\n",
        "\n",
        "BOT_TOKEN & CHAT_ID → Telegram alert ke liye.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "03qXVL8IPPim",
        "outputId": "88ed522c-0d77-472c-c8de-735f01fa0b7d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nScaler → data ko 0–1 ke range me laya jata hai.\\n\\nFinBERT model → financial sentiment analysis ke liye pretrained model.\\n\\nDB_FILE → SQLite database file.\\n\\nBOT_TOKEN & CHAT_ID → Telegram alert ke liye.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def init_db():\n",
        "    conn = sqlite3.connect(DB_FILE)\n",
        "    c = conn.cursor()\n",
        "    c.execute('''CREATE TABLE IF NOT EXISTS predictions\n",
        "                 (ticker TEXT, predicted_price REAL, date TEXT)''')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\"\"\"\n",
        "Agar database nahi hai to predictions table create hota hai.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bVFVazNMPPld",
        "outputId": "6aca62d9-1a8a-4212-e4c5-526de978213d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAgar database nahi hai to predictions table create hota hai.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_db(ticker, price):\n",
        "    conn = sqlite3.connect(DB_FILE)\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"INSERT INTO predictions VALUES (?, ?, ?)\", (ticker, price, datetime.datetime.now().strftime('%Y-%m-%d')))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "  # Har prediction DB me save hoti hai.\n",
        "\n"
      ],
      "metadata": {
        "id": "SmrZkwzYPPod"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stock_data(ticker):\n",
        "    df = yf.download(ticker, period=\"1y\")\n",
        "    return df[['Close']]\n",
        "\n",
        "    # Yahoo Finance se 1 saal ka closing price data fetch hota hai.\n"
      ],
      "metadata": {
        "id": "3idnOzWlPPrU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(data):\n",
        "    data_scaled = scaler.fit_transform(data)\n",
        "    x, y = [], []\n",
        "    for i in range(60, len(data_scaled)):\n",
        "        x.append(data_scaled[i-60:i, 0])  # past 60 days\n",
        "        y.append(data_scaled[i, 0])       # next day\n",
        "    return np.array(x), np.array(y)\n",
        "\n",
        "# Sliding window method – last 60 days input, agla din output."
      ],
      "metadata": {
        "id": "FQd7tSK1PPuK"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model():\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(units=50, return_sequences=True, input_shape=(60, 1)))\n",
        "    model.add(LSTM(units=50))\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "    return model\n",
        "\n",
        "# Simple 2-layer LSTM + Dense output model."
      ],
      "metadata": {
        "id": "5y3m66wmPPxU"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_stock(ticker):\n",
        "    df = get_stock_data(ticker)\n",
        "    if df.empty:\n",
        "        raise Exception(\"Invalid stock ticker or no data available.\")\n",
        "    x, y = prepare_data(df.values)\n",
        "    x = x.reshape((x.shape[0], x.shape[1], 1))\n",
        "    model = build_model()\n",
        "    model.fit(x, y, epochs=5, batch_size=32, verbose=0)\n",
        "    latest_60 = scaler.transform(df[-60:].values)\n",
        "    input_data = latest_60.reshape(1, 60, 1)\n",
        "    predicted_price = model.predict(input_data)[0][0]\n",
        "    predicted_price = scaler.inverse_transform([[predicted_price]])[0][0]\n",
        "    return round(predicted_price, 2), df\n",
        "\n",
        "# Training + prediction → predicted closing price nikalta hai."
      ],
      "metadata": {
        "id": "ZsZOz3LLPPz7"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_news(ticker):\n",
        "    search_url = f\"https://www.google.com/search?q={ticker}+stock+news\"\n",
        "    headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "    try:\n",
        "        page = requests.get(search_url, headers=headers, timeout=10)\n",
        "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
        "        news_items = soup.select('div.BNeawe.vvjwJb.AP7Wnd')\n",
        "        return [item.get_text() for item in news_items[:5]]\n",
        "    except:\n",
        "        return [\"Unable to fetch news at the moment.\"]\n",
        "\n",
        "# Google news scrape, top 5 headlines."
      ],
      "metadata": {
        "id": "0Rb88JuCPP2w"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_news(news_list):\n",
        "    results = []\n",
        "    for news in news_list:\n",
        "        inputs = tokenizer(news, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "        with torch.no_grad():\n",
        "            outputs = sentiment_model(**inputs)\n",
        "            scores = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "            label_idx = torch.argmax(scores).item()\n",
        "            confidence = scores[0][label_idx].item()\n",
        "        results.append((news, label_map[label_idx], confidence))\n",
        "    return results\n",
        "# FinBERT model se sentiment analysis (positive, neutral, negative)."
      ],
      "metadata": {
        "id": "n56W6ST3PP5l"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_chart(df, ticker):\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    df['Close'].plot(title=f\"{ticker.upper()} Closing Price (Past Year)\")\n",
        "    chart_file = f\"{ticker}_chart.png\"\n",
        "    plt.savefig(chart_file)\n",
        "    plt.close()\n",
        "    return chart_file\n",
        "\n",
        "# Stock ka chart banta hai aur image save hoti hai."
      ],
      "metadata": {
        "id": "yFlDraFnPP8b"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pdf(ticker, predicted_price, news_analysis, chart_path):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.cell(200, 10, txt=f\"Stock Report for {ticker.upper()} - {datetime.datetime.now().strftime('%Y-%m-%d')}\", ln=True)\n",
        "    pdf.cell(200, 10, txt=f\"Predicted Price: ${predicted_price}\", ln=True)\n",
        "    pdf.image(chart_path, w=180)\n",
        "    pdf.cell(200, 10, txt=\"News Sentiment Analysis:\", ln=True)\n",
        "    for news, label, score in news_analysis:\n",
        "        pdf.multi_cell(0, 10, f\"- {news}\\nSentiment: {label.upper()} (Confidence: {round(score, 2)})\\n\")\n",
        "    filename = f\"{ticker}_report.pdf\"\n",
        "    pdf.output(filename)\n",
        "    return filename\n",
        "\n",
        "# PDF banata hai: prediction + chart + news sentiment."
      ],
      "metadata": {
        "id": "B4hYWAkOPP_b"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speak_summary(ticker, predicted_price):\n",
        "    message = f\"The predicted price for {ticker.upper()} is {predicted_price} dollars.\"\n",
        "    tts = gTTS(text=message, lang='en')\n",
        "    filename = f\"{ticker}_summary.mp3\"\n",
        "    tts.save(filename)\n",
        "    return filename\n",
        "\n",
        "# MP3 voice file generate karta hai."
      ],
      "metadata": {
        "id": "fkqLF3unPQCU"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def send_telegram_alert(ticker, price):\n",
        "    try:\n",
        "        bot = telebot.TeleBot(BOT_TOKEN)\n",
        "        msg = f\"Prediction Alert!\\n{ticker.upper()} expected price: ${price}\"\n",
        "        bot.send_message(CHAT_ID, msg)\n",
        "    except:\n",
        "        print(\"Telegram alert failed. Check your token or chat ID.\")\n",
        "\n",
        "# Telegram bot pe alert bhejta hai."
      ],
      "metadata": {
        "id": "I1KVWaEJRkB4"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def full_analysis(ticker):\n",
        "    try:\n",
        "        predicted_price, df = predict_stock(ticker)\n",
        "        news = fetch_news(ticker)\n",
        "        analysis = analyze_news(news)\n",
        "        chart_path = create_chart(df, ticker)\n",
        "        pdf_path = create_pdf(ticker, predicted_price, analysis, chart_path)\n",
        "        voice_path = speak_summary(ticker, predicted_price)\n",
        "        save_to_db(ticker, predicted_price)\n",
        "        send_telegram_alert(ticker, predicted_price)\n",
        "        return f\"{ticker.upper()} predicted price: ${predicted_price}\", pdf_path, voice_path\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\", None, None\n",
        "\n",
        "#Sab modules ek jagah execute karta hai → prediction + PDF + voice + DB + Telegram."
      ],
      "metadata": {
        "id": "ybMSwWqXRkE_"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "iface = gr.Interface(\n",
        "    fn=full_analysis,\n",
        "    inputs=gr.Textbox(label=\"Enter Stock Ticker (e.g., AAPL)\", placeholder=\"Type a stock symbol...\"),\n",
        "    outputs=[\n",
        "        gr.Text(label=\"Prediction Result\"),\n",
        "        gr.File(label=\"Download PDF Report\"),\n",
        "        gr.File(label=\"Voice Summary (MP3)\")\n",
        "    ],\n",
        "    title=\"Stock Market AI + Voice + Alerts\",\n",
        "    description=\"LSTM stock predictor + FinBERT news sentiment + PDF + Chart + Voice summary + Telegram alert + SQLite logging\"\n",
        ")\n",
        "\n",
        "# Simple web app jaha ticker dal kar analysis run hota hai."
      ],
      "metadata": {
        "id": "kMZI7sxORkH3"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/analyze', methods=['POST'])\n",
        "def analyze():\n",
        "    data = request.json\n",
        "    ticker = data.get('ticker')\n",
        "    if not ticker:\n",
        "        return jsonify({\"error\": \"No ticker provided\"})\n",
        "    prediction, pdf_path, voice_path = full_analysis(ticker)\n",
        "    return jsonify({\"prediction\": prediction, \"pdf_path\": pdf_path, \"voice_path\": voice_path})\n",
        "\n",
        "@app.route('/download/<filename>')\n",
        "def download_file(filename):\n",
        "    if os.path.exists(filename):\n",
        "        return send_file(filename, as_attachment=True)\n",
        "    else:\n",
        "        return \"File not found\", 404\n",
        "\n",
        "# Flask API banata hai jo external requests handle karega."
      ],
      "metadata": {
        "id": "YaUUukI1RkK3"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_db()\n",
        "iface.launch(share=True)\n",
        "\n",
        "# DB init + Gradio launch."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "X4y0xYrsRkNv",
        "outputId": "7e7a0daf-13c9-43ad-ae83-9f311c70c6cc"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1264e21e193292dfe7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1264e21e193292dfe7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "z1EVcvQTRkQa",
        "outputId": "ac19ef21-5c3c-4494-daeb-0fee28390e59"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://7a9c539cf3ea5ad8b6.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7a9c539cf3ea5ad8b6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vE-hg0tERkTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "chMcOywuRkXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dG7S9AxXPQEy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}